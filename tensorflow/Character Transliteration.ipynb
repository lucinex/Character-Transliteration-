{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Character Transliteration.ipynb","provenance":[],"mount_file_id":"17uDJaLz9Z2Gv6UZQR96nYu8AGvM9fPwv","authorship_tag":"ABX9TyPhPvD+XNOE8nCMP070+5uH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjoQND3mow91","executionInfo":{"status":"ok","timestamp":1631245991220,"user_tz":-330,"elapsed":5040,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"7ec6116d-925e-48ba-847f-14ff343c3b9c"},"source":["!pip install tensorflow_text"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_text\n","  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n","Requirement already satisfied: tensorflow<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.6.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.15.0)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (2.6.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.12)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.1.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.3.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (2.6.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.12.1)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.6.3)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.1.2)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.2.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.12.0)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.19.5)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (5.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.37.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.17.3)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (2.6.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.39.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.7.4.3)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.34.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.3.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (57.4.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.4.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (2.23.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (4.2.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (4.6.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.5.0)\n","Installing collected packages: tensorflow-text\n","Successfully installed tensorflow-text-2.6.0\n"]}]},{"cell_type":"code","metadata":{"id":"UFg-N5QVjt5N","executionInfo":{"status":"ok","timestamp":1631246003594,"user_tz":-330,"elapsed":3243,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["\n","import pandas as pd\n","import numpy as np\n","import os, io, json\n","import pickle\n","\n","import typing\n","from typing import Any, Tuple\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers.experimental import preprocessing\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import tensorflow_text as tf_text\n","from tensorflow.keras import models, layers, preprocessing as kprocessing\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WPshWXm6IS8","executionInfo":{"status":"ok","timestamp":1631246010365,"user_tz":-330,"elapsed":5588,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"15b5a296-ee28-4c23-9a85-c1196d455617"},"source":["\n","try: # detect TPUs\n","  tpu = None\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","except ValueError: # detect GPUs\n","  #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n","  #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n","  strategy = tf.distribute.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n","\n","print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n","Number of accelerators:  1\n"]}]},{"cell_type":"code","metadata":{"id":"5B39eBiNpbRd","executionInfo":{"status":"ok","timestamp":1631246010366,"user_tz":-330,"elapsed":4,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["pth_1 =  \"/content/drive/MyDrive/Dataset/Dakshina/hi/hi.translit.sampled.train.tsv\""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"9YQ3J-L4kPYN","executionInfo":{"status":"ok","timestamp":1631072490956,"user_tz":-330,"elapsed":516,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["def load_data(path):\n","  \n","  df = pd.read_csv(pth_1,sep=\"\\t\",names=[\"Hindi\",\"roman\",\"freq\"]) \n","  df = df[['Hindi','roman']]\n","  hindi = np.asarray(df['Hindi'],dtype = str)\n","  roman = np.asarray(df['roman'],dtype =str)\n","  #hindi = hindi.astype(str)\n","  #roman = roman.astype(str)\n","  tokenizer = tf_text.UnicodeCharTokenizer()\n","  inp = tokenizer.tokenize([hi for hi in hindi])\n","  tokenizer.\n","  targ = tokenizer.tokenize([targ for targ in roman])\n","  #inp = [np.asarray([i for i in inp],dtype=np.str) for inp in hindi]\n","  #targ = [[\"<sos>\"]+[j for j in targ]+['<eos>'] for targ in roman]\n","\n","  return  inp,targ"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zfe-ClLn9FQv","executionInfo":{"status":"ok","timestamp":1631073032114,"user_tz":-330,"elapsed":370,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"a593d195-7e77-4b4b-fe01-af5886d8b491"},"source":["tokenizer = tf_text.UnicodeCharTokenizer()\n","tokenizer.tokenize(['abc'])\n","tokenizer."],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[97, 98, 99]]>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Tr05i_ufrMtB","executionInfo":{"status":"ok","timestamp":1631072499847,"user_tz":-330,"elapsed":1728,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["inp,targ = load_data(pth_1)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vwgdLFV6Govr","executionInfo":{"status":"ok","timestamp":1630948629515,"user_tz":-330,"elapsed":420,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"fc998db6-81e0-45c9-91b2-2dfd09afad9c"},"source":["x = inp[0]\n","x = x.numpy()\n","x = x.tolist()\n","x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2309, 2306]"]},"metadata":{},"execution_count":157}]},{"cell_type":"code","metadata":{"id":"F7lcmfbDg4qe","executionInfo":{"status":"ok","timestamp":1631072956471,"user_tz":-330,"elapsed":409,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["tokens = inp[:64]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"YcmUoxrBjAmp","executionInfo":{"status":"ok","timestamp":1631246011822,"user_tz":-330,"elapsed":813,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["df = pd.read_csv(pth_1,sep=\"\\t\",names=[\"Hindi\",\"roman\",\"freq\"]) \n","df = df[['Hindi','roman']]\n","hindi = df['Hindi']\n","tokenizer_hi = Tokenizer(\n","    char_level=True,oov_token='<UNK>'\n",")\n","tokenizer_hi.fit_on_texts(hindi)\n","vocab_hi = tokenizer_hi.word_index\n","text_hi = tokenizer_hi.texts_to_sequences(hindi)\n","#text_hi = tf.ragged.stack(text)\n","x = kprocessing.sequence.pad_sequences(text_hi, \n","                     padding=\"post\", truncating=\"post\",)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jELteLOp1Pml","executionInfo":{"status":"ok","timestamp":1631162024261,"user_tz":-330,"elapsed":373,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"dae62e2a-1612-4c9b-f6d7-45ddd38c894c"},"source":[""],"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'अ'"]},"metadata":{},"execution_count":117}]},{"cell_type":"code","metadata":{"id":"eO72PoRx1PGC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNE50AxysSiW","executionInfo":{"status":"ok","timestamp":1631246036100,"user_tz":-330,"elapsed":2,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["tokenizer_en = Tokenizer(\n","    char_level=True,oov_token='<UNK>',  \n",")\n","roman = np.asarray(df['roman'],dtype = str)\n","\n","tokenizer_en.fit_on_texts(roman)\n","text_en = tokenizer_en.texts_to_sequences(roman)\n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"veVrsnH81Apx","executionInfo":{"status":"ok","timestamp":1631246038555,"user_tz":-330,"elapsed":378,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"14c5c081-9824-4021-cc79-08f5948a040b"},"source":["#tokenizer_en.index_word[0] = ''\n","\n","start_token = len(tokenizer_en.index_word)+1\n","end_token = len(tokenizer_en.index_word)+2\n","print(start_token,end_token)\n","new_text_en = []\n","for i in text_en:\n","  i = [start_token] + i + [end_token]\n","  new_text_en.append(i)\n","\n","tokenizer_en.index_word[start_token] = '<sos>'\n","tokenizer_en.word_index['<sos>'] = start_token\n","tokenizer_en.index_word[end_token] = '<eos>'\n","tokenizer_en.word_index['<eos>'] = end_token\n","\n","y = kprocessing.sequence.pad_sequences(new_text_en, \n","                     padding=\"post\", truncating=\"post\")"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["28 29\n"]}]},{"cell_type":"code","metadata":{"id":"BuaNbmQV3U7a"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JMVPAH_w3R-S","executionInfo":{"status":"ok","timestamp":1631163676156,"user_tz":-330,"elapsed":636,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":[""],"execution_count":157,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ggSv-E6S7zNI","executionInfo":{"status":"ok","timestamp":1631162589232,"user_tz":-330,"elapsed":650,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"d8b535ff-1fb7-416b-e0ed-ac7c0b081f6d"},"source":[""],"execution_count":128,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: '',\n"," '<UNK>': 1,\n"," 'a': 2,\n"," 'b': 19,\n"," 'c': 21,\n"," 'd': 11,\n"," 'e': 9,\n"," 'f': 24,\n"," 'g': 20,\n"," 'h': 5,\n"," 'i': 4,\n"," 'j': 22,\n"," 'k': 12,\n"," 'l': 13,\n"," 'm': 15,\n"," 'n': 3,\n"," 'o': 10,\n"," 'p': 17,\n"," 'q': 27,\n"," 'r': 6,\n"," 's': 8,\n"," 't': 7,\n"," 'u': 14,\n"," 'v': 18,\n"," 'w': 23,\n"," 'x': 26,\n"," 'y': 16,\n"," 'z': 25}"]},"metadata":{},"execution_count":128}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"eGvF9SV6ctQC","executionInfo":{"status":"ok","timestamp":1631106266866,"user_tz":-330,"elapsed":546,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"dc29b886-94af-470d-8451-d5a9bf988699"},"source":["tokenizer_en.index_word[1]"],"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<UNK>'"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"X2LNnGcUgHNk","executionInfo":{"status":"ok","timestamp":1631097214824,"user_tz":-330,"elapsed":556,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["class ShapeChecker():\n","  def __init__(self):\n","    # Keep a cache of every axis-name seen\n","    self.shapes = {}\n","\n","  def __call__(self, tensor, names, broadcast=False):\n","    if not tf.executing_eagerly():\n","      return\n","\n","    if isinstance(names, str):\n","      names = (names,)\n","\n","    shape = tf.shape(tensor)\n","    rank = tf.rank(tensor)\n","\n","    if rank != len(names):\n","      raise ValueError(f'Rank mismatch:\\n'\n","                       f'    found {rank}: {shape.numpy()}\\n'\n","                       f'    expected {len(names)}: {names}\\n')\n","\n","    for i, name in enumerate(names):\n","      if isinstance(name, int):\n","        old_dim = name\n","      else:\n","        old_dim = self.shapes.get(name, None)\n","      new_dim = shape[i]\n","\n","      if (broadcast and new_dim == 1):\n","        continue\n","\n","      if old_dim is None:\n","        # If the axis name is new, add its length to the cache.\n","        self.shapes[name] = new_dim\n","        continue\n","\n","      if new_dim != old_dim:\n","        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n","                         f\"    found: {new_dim}\\n\"\n","                         f\"    expected: {old_dim}\\n\")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIu63IxptKgl","executionInfo":{"status":"ok","timestamp":1631247215290,"user_tz":-330,"elapsed":393,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n","    super(Encoder, self).__init__()\n","    self.enc_units = enc_units\n","    self.input_vocab_size = input_vocab_size\n","    \n","    \n","    # The embedding layer converts tokens to vectors\n","    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n","                                               embedding_dim)\n","\n","    # The GRU RNN layer processes those vectors sequentially.\n","    \n","    self.gru1 = tf.keras.layers.Bidirectional( tf.keras.layers.GRU(units=self.enc_units, dropout=0.5,return_sequences=True,return_state=True))\n","    self.gru = tf.keras.layers.GRU(self.enc_units,\n","                                   dropout=0.4,\n","                                   # Return the sequence and state\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.dense = tf.keras.layers.Dense(units=self.enc_units,use_bias=False)\n","  def call(self, tokens, state=None):\n","    #tokens = self.input1(tokens)\n","    #shape_checker = ShapeChecker()\n","    #shape_checker(tokens, ('batch', 's'))\n","\n","    # 2. The embedding layer looks up the embedding for each token.\n","    vectors = self.embedding(tokens)\n","    #shape_checker(vectors, ('batch', 's', 'embed_dim'))\n","\n","    # 3. The GRU processes the embedding sequence.\n","    #    output shape: (batch, s, enc_units)\n","    #    state shape: (batch, enc_units)\n","    \n","    output, s1,s2 = self.gru1(vectors, initial_state=state)\n","    \n","    output, state = self.gru(output, initial_state=state)\n","    state = tf.keras.layers.concatenate([s1,s2,state], axis=1)\n","    state = self.dense(state)\n","    \n","    #shape_checker(output, ('batch', 's', 'enc_units'))\n","    #shape_checker(state, ('batch', 'enc_units'))\n","\n","    # 4. Returns the new sequence and its state.\n","    return output, state"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"SIN2lH25wdqo","executionInfo":{"status":"ok","timestamp":1631246449075,"user_tz":-330,"elapsed":688,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["embedding_dim =256\n","units =1024"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"bjRlxXnztNdn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631247192640,"user_tz":-330,"elapsed":3825,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"dce88146-410c-4e0e-cdcb-b18e073eb4fb"},"source":["# Convert the input text to tokens.\n","example_tokens = x[:64]\n","\n","# Encode the input sequence.\n","encoder = Encoder(len(vocab_hi),\n","                  embedding_dim, units)\n","example_enc_output, example_enc_state = encoder(example_tokens)\n","\n","#print(f'Input batch, shape (batch): {example_input_batch.shape}')\n","print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n","print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n","print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 1024)\n","Input batch tokens, shape (batch, s): (64, 19)\n","Encoder output, shape (batch, s, units): (64, 19, 1024)\n","Encoder state, shape (batch, units): (64, 1024)\n"]}]},{"cell_type":"code","metadata":{"id":"9cgPn4PI5uAu","executionInfo":{"status":"ok","timestamp":1631247385406,"user_tz":-330,"elapsed":393,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super().__init__()\n","    # For Eqn. (4), the  Bahdanau attention\n","    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n","    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n","\n","    self.attention = tf.keras.layers.AdditiveAttention()\n","\n","  def call(self, query, value, mask):\n","    \n","    # From Eqn. (4), `W1@ht`.\n","    w1_query = self.W1(query)\n","    # ('batch', 't', 'attn_units'))\n","\n","    # From Eqn. (4), `W2@hs`.\n","    w2_key = self.W2(value)\n","    #('batch', 's', 'attn_units'))\n","\n","    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n","    value_mask = mask\n","\n","    context_vector, attention_weights = self.attention(\n","        inputs = [w1_query, value, w2_key],\n","        mask=[query_mask, value_mask],\n","        return_attention_scores = True,\n","    )\n","    #context_vector, ('batch', 't', 'value_units'))\n","    #attention_weights, ('batch', 't', 's'))\n","\n","    return context_vector, attention_weights"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXXeVsDxrfgp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631247388373,"user_tz":-330,"elapsed":408,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"36f69ce6-987e-49eb-ec5f-01f9c7940d97"},"source":["attention_layer = BahdanauAttention(units)\n","# Later, the decoder will generate this attention query\n","example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n","\n","# Attend to the encoded tokens\n","\n","context_vector, attention_weights = attention_layer(\n","    query=example_attention_query,\n","    value=example_enc_output,\n","    mask=(example_tokens != 0))\n","\n","print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n","print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"],"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention result shape: (batch_size, query_seq_length, units):           (64, 2, 1024)\n","Attention weights shape: (batch_size, query_seq_length, value_seq_length): (64, 2, 19)\n"]}]},{"cell_type":"code","metadata":{"id":"u18AvAHdrVrG","colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"status":"ok","timestamp":1631097232884,"user_tz":-330,"elapsed":772,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"6031cc50-f6eb-4675-efdf-788afd7baabb"},"source":["plt.subplot(1, 2, 1)\n","plt.pcolormesh(attention_weights[:, 0, :])\n","plt.title('Attention weights')\n","\n","plt.subplot(1, 2, 2)\n","plt.pcolormesh(example_tokens != 0)\n","plt.title('Mask')"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'Mask')"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"K6AOCZ9B8jRg","executionInfo":{"status":"ok","timestamp":1631163183137,"user_tz":-330,"elapsed":370,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":[""],"execution_count":140,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZCqJPQxZ8i73","executionInfo":{"status":"ok","timestamp":1631247377186,"user_tz":-330,"elapsed":393,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["class DecoderInput(typing.NamedTuple):\n","  new_tokens: Any\n","  enc_output: Any\n","  mask: Any\n","\n","class DecoderOutput(typing.NamedTuple):\n","  logits: Any\n","  attention_weights: Any\n","\n","  \n","class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n","    super(Decoder, self).__init__()\n","    self.dec_units = dec_units\n","    self.output_vocab_size = output_vocab_size\n","    self.embedding_dim = embedding_dim\n","\n","    # For Step 1. The embedding layer convets token IDs to vectors\n","    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n","                                               embedding_dim)\n","\n","    # For Step 2. The RNN keeps track of what's been generated so far.\n","    self.gru = tf.keras.layers.GRU(self.dec_units, dropout=0.25,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","\n","    self.gru2 = tf.keras.layers.GRU(self.dec_units, dropout=0.6,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    # For step 3. The RNN output will be the query for the attention layer.\n","    self.attention = BahdanauAttention(self.dec_units)\n","\n","    # For step 4. Eqn. (3): converting `ct` to `at`\n","    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n","                                    use_bias=False)\n","\n","    # For step 5. This fully connected layer produces the logits for each\n","    # output token.\n","    self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n","\n","\n","  def call(self,\n","         inputs: DecoderInput,\n","         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n","  \n","    #if state is not None:\n","      \n","  # Step 1. Lookup the embeddings\n","    vectors = self.embedding(inputs.new_tokens)\n","    #shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n","\n","  # Step 2. Process one step with the RNN\n","    rnn_output, s1 = self.gru(vectors, initial_state=state)\n","    rnn_output, state = self.gru2(rnn_output, initial_state=state)\n","    #shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n","    #shape_checker(state, ('batch', 'dec_units'))\n","\n","  # Step 3. Use the RNN output as the query for the attention over the\n","  # encoder output.\n","    context_vector, attention_weights = self.attention(\n","        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n","  #shape_checker(context_vector, ('batch', 't', 'dec_units'))\n","  #shape_checker(attention_weights, ('batch', 't', 's'))\n","\n","  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n","  #     [ct; ht] shape: (batch t, value_units + query_units)\n","    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n","\n","  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n","    attention_vector = self.Wc(context_and_rnn_output)\n"," # shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n","\n","  # Step 5. Generate logit predictions:\n","    logits = self.fc(attention_vector)\n","  #shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n","\n","    return DecoderOutput(logits, attention_weights), state"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zv992WAr-Ps5","executionInfo":{"status":"ok","timestamp":1631247396364,"user_tz":-330,"elapsed":579,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["decoder = Decoder((len(tokenizer_en.index_word)+1),\n","                  embedding_dim, units)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"2cuDddsh-Pv5","executionInfo":{"status":"ok","timestamp":1631247399305,"user_tz":-330,"elapsed":396,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["# Convert the target sequence, and collect the \"[START]\" tokens\n","example_output_tokens = y[:64]\n","\n","#start_index = token.index('[START]')\n","first_token = tf.constant([[len(tokenizer_en.index_word)]] * example_output_tokens.shape[0])"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"utPLoPCZ-Pyi","executionInfo":{"status":"ok","timestamp":1631247404513,"user_tz":-330,"elapsed":406,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"4a476a64-c762-405d-e846-0fe63c76afac"},"source":["decoder.output_vocab_size, len(tokenizer_en.word_index)"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(30, 29)"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUL9OxM3-P06","executionInfo":{"status":"ok","timestamp":1631247408100,"user_tz":-330,"elapsed":415,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"404172f1-8970-48fe-d899-599e6e876ec8"},"source":["# Run the decoder\n","dec_result, dec_state = decoder(\n","    inputs = DecoderInput(new_tokens=first_token,\n","                          enc_output=example_enc_output,\n","                          mask=(example_tokens != 0)),\n","    state = example_enc_state\n",")\n","\n","print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n","print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["logits shape: (batch_size, t, output_vocab_size) (64, 1, 30)\n","state shape: (batch_size, dec_units) (64, 1024)\n"]}]},{"cell_type":"code","metadata":{"id":"GKDAmqrD-P3O","executionInfo":{"status":"ok","timestamp":1631102497604,"user_tz":-330,"elapsed":548,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["sampled_token = tf.random.categorical(dec_result.logits[:,0,:],num_samples=1)\n","dec_result, dec_state = decoder(\n","    inputs = DecoderInput(new_tokens=sampled_token,\n","                          enc_output=example_enc_output,\n","                          mask=(example_tokens != 0)),\n","    state = example_enc_state\n",")\n"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aRJymrZaFDl","executionInfo":{"status":"ok","timestamp":1631247445439,"user_tz":-330,"elapsed":368,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["class MaskedLoss(tf.keras.losses.Loss):\n","  def __init__(self):\n","    self.name = 'masked_loss'\n","    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","\n","  def __call__(self, y_true, y_pred):\n","    #shape_checker = ShapeChecker()\n","    #shape_checker(y_true, ('batch', 't'))\n","    #shape_checker(y_pred, ('batch', 't', 'logits'))\n","\n","    # Calculate the loss for each item in the batch.\n","    loss = self.loss(y_true, y_pred)\n","    #shape_checker(loss, ('batch', 't'))\n","\n","    # Mask off the losses on padding.\n","    mask = tf.cast(y_true != 0, tf.float32)\n","    #shape_checker(mask, ('batch', 't'))\n","    loss *= mask\n","\n","    # Return the total.\n","    return tf.reduce_sum(loss)"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5THwdkkSQij","executionInfo":{"status":"ok","timestamp":1631247453310,"user_tz":-330,"elapsed":381,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["class TrainTranslator(tf.keras.Model):\n","  def __init__(self, embedding_dim, units,\n","               input_text_vocab,\n","               output_text_vocab, \n","               use_tf_function=True):\n","    super().__init__()\n","    # Build the encoder and decoder\n","    self.input_text_vocab = input_text_vocab\n","    self.output_text_vocab = output_text_vocab\n","\n","    encoder = Encoder((len(self.input_text_vocab)+1),\n","                      embedding_dim, units)\n","    decoder = Decoder((len(output_text_vocab)+1),\n","                      embedding_dim, units)\n","\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    \n","    self.use_tf_function = use_tf_function\n","    #self.shape_checker = ShapeChecker()\n","\n","  def train_step(self, inputs):\n","    #self.shape_checker = ShapeChecker()\n","    if self.use_tf_function:\n","      return self._tf_train_step(inputs)\n","    else:\n","      return self._train_step(inputs)\n","  def _preprocess(self, input_tokens, target_tokens):\n","    #self.shape_checker(input_text, ('batch',))\n","    #self.shape_checker(target_text, ('batch',))\n","\n","    # Convert the text to token IDs\n","    #input_tokens = self.input_text_processor(input_text)\n","    #target_tokens = self.output_text_processor(target_text)\n","    #self.shape_checker(input_tokens, ('batch', 's'))\n","    #self.shape_checker(target_tokens, ('batch', 't'))\n","\n","    # Convert IDs to masks.\n","    input_mask = input_tokens != 0\n","    #self.shape_checker(input_mask, ('batch', 's'))\n","\n","    target_mask = target_tokens != 0\n","    #self.shape_checker(target_mask, ('batch', 't'))\n","\n","    return input_tokens, input_mask, target_tokens, target_mask\n","  def _train_step(self, inputs):\n","    input_text, target_text = inputs  \n","\n","    (input_tokens, input_mask,target_tokens, target_mask) = self._preprocess(input_text, target_text)\n","\n","    max_target_length = target_tokens.shape[1]\n","\n","    with tf.GradientTape() as tape:\n","    # Encode the input\n","      enc_output, enc_state = self.encoder(input_tokens)\n","      #self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n","      #self.shape_checker(enc_state, ('batch', 'enc_units'))\n","\n","      #  Initialize the decoder's state to the encoder's final state.\n","    # This only works if the encoder and decoder have the same number of\n","    # units.\n","      dec_state = enc_state\n","      loss = tf.constant(0.0)\n","\n","      for t in range(max_target_length-1):\n","        # Pass in two tokens from the target sequence:\n","      # 1. The current input to the decoder.\n","      # 2. The target the target for the decoder's next prediction.\n","        \n","        new_tokens = target_tokens[:, t:t+2]\n","        step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n","                                             enc_output, dec_state)\n","        loss = loss + step_loss\n","\n","    # Average the loss over all non padding tokens.\n","        average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n","\n","  # Apply an optimization step\n","    variables = self.trainable_variables \n","    gradients = tape.gradient(average_loss, variables)\n","    self.optimizer.apply_gradients(zip(gradients, variables))\n","\n","  # Return a dict mapping metric names to current value\n","    return {'batch_loss': average_loss}\n","\n","\n","  def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n","    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n","    \n","    # Run the decoder one step.\n","    decoder_input = DecoderInput(new_tokens=input_token,\n","                               enc_output=enc_output,\n","                               mask=input_mask)\n","\n","    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n","    #self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n","    #self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n","    #self.shape_checker(dec_state, ('batch', 'dec_units'))\n","\n","  # `self.loss` returns the total for non-padded tokens\n","    y = target_token\n","    y_pred = dec_result.logits\n","    step_loss = self.loss(y, y_pred)\n","\n","    return step_loss, dec_state\n","  \n","  @tf.function(input_signature=[[tf.TensorSpec(dtype=tf.int32, shape=[None]),\n","                               tf.TensorSpec(dtype=tf.int32, shape=[None])]])\n","  def _tf_train_step(self, inputs):\n","    return self._train_step(inputs)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ExeNgW96-3G"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jx4f6hz9SQlV","executionInfo":{"status":"ok","timestamp":1631163933792,"user_tz":-330,"elapsed":2,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["translator = TrainTranslator(\n","    embedding_dim, units,\n","    input_text_vocab = tokenizer_hi.word_index,\n","    output_text_vocab = tokenizer_en.word_index,\n","    use_tf_function=False)\n","\n","# Configure the loss and optimizer\n","translator.compile(\n","    optimizer=tf.optimizers.Adam(),\n","    loss=MaskedLoss(),\n",")"],"execution_count":160,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msSJ4rNkSQoQ","executionInfo":{"status":"ok","timestamp":1631163943719,"user_tz":-330,"elapsed":1071,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"e31ee139-893e-41d9-c516-a497d90eb4bb"},"source":["for n in range(1):\n","  print(translator.train_step([x[:64], y[:64]]))\n","print()"],"execution_count":161,"outputs":[{"output_type":"stream","name":"stdout","text":["{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.0016494>}\n","\n"]}]},{"cell_type":"code","metadata":{"id":"HWQVvCFAd4KD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cz2j5knad4tG","executionInfo":{"status":"ok","timestamp":1631247534805,"user_tz":-330,"elapsed":409,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["with strategy.scope():\n","  translator = TrainTranslator(\n","    embedding_dim, units,\n","    input_text_vocab = tokenizer_hi.word_index,\n","    output_text_vocab = tokenizer_en.word_index,\n","    use_tf_function=False)\n","\n","# Configure the loss and optimizer\n","  translator.compile(\n","    optimizer=tf.optimizers.Adam(),\n","    loss=MaskedLoss(),\n","  )"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"35f2vsMTSQqv","executionInfo":{"status":"ok","timestamp":1631125394935,"user_tz":-330,"elapsed":526,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["translator.use_tf_function = False"],"execution_count":227,"outputs":[]},{"cell_type":"code","metadata":{"id":"DsRuoMsaWXqb"},"source":["translator = training.model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xH9lw1xkS_R","executionInfo":{"status":"ok","timestamp":1631252544031,"user_tz":-330,"elapsed":4968139,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"8ea22b24-28a8-43e5-ce99-d257198b58ed"},"source":["training = translator.fit(x=x, y=y, batch_size=128, \n","                     epochs=20,  shuffle=True, verbose=1)"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","346/346 [==============================] - 327s 707ms/step - batch_loss: 0.9345\n","Epoch 2/20\n","346/346 [==============================] - 244s 705ms/step - batch_loss: 0.3790\n","Epoch 3/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.3182\n","Epoch 4/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.2881\n","Epoch 5/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.2625\n","Epoch 6/20\n","346/346 [==============================] - 244s 705ms/step - batch_loss: 0.2422\n","Epoch 7/20\n","346/346 [==============================] - 244s 705ms/step - batch_loss: 0.2292\n","Epoch 8/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.2147\n","Epoch 9/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.2041\n","Epoch 10/20\n","346/346 [==============================] - 244s 705ms/step - batch_loss: 0.1945\n","Epoch 11/20\n","346/346 [==============================] - 244s 705ms/step - batch_loss: 0.1867\n","Epoch 12/20\n","346/346 [==============================] - 244s 705ms/step - batch_loss: 0.1781\n","Epoch 13/20\n","346/346 [==============================] - 244s 705ms/step - batch_loss: 0.1712\n","Epoch 14/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.1682\n","Epoch 15/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.1697\n","Epoch 16/20\n","346/346 [==============================] - 244s 705ms/step - batch_loss: 0.1618\n","Epoch 17/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.1577\n","Epoch 18/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.1570\n","Epoch 19/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.1544\n","Epoch 20/20\n","346/346 [==============================] - 244s 706ms/step - batch_loss: 0.1584\n"]}]},{"cell_type":"code","metadata":{"id":"KavRf0KupsFi","executionInfo":{"status":"ok","timestamp":1631252544948,"user_tz":-330,"elapsed":931,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["pth_model = \"/content/drive/MyDrive/Dataset/Dakshina/hi/tensorflow/char_mod_3\"\n","translator_1 = training.model\n","save_model(translator_1,pth_model)"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"YT7KXD1JoyC0","executionInfo":{"status":"ok","timestamp":1631175564214,"user_tz":-330,"elapsed":657,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":[""],"execution_count":181,"outputs":[]},{"cell_type":"code","metadata":{"id":"jqeCnUGylpWy","executionInfo":{"status":"ok","timestamp":1631247470885,"user_tz":-330,"elapsed":386,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["def _save_weights(model,save_folder):\n","    save_path = os.path.join(save_folder , \"weights.h5\")\n","    model.save_weights(save_path)\n","\n","def _create_folder_if_it_dosent_exist(folder):\n","    if not os.path.exists(folder):\n","      os.makedirs(folder)\n","def save_model(model, save_folder):\n","    _create_folder_if_it_dosent_exist(save_folder)\n","    #_save_parameters(model, save_folder)\n","    _save_weights(model,save_folder)\n"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"gu9B83ujlq3S","executionInfo":{"status":"ok","timestamp":1631171597324,"user_tz":-330,"elapsed":960,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":[""],"execution_count":169,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"GyFrxNsuZUGA","executionInfo":{"status":"ok","timestamp":1631163293861,"user_tz":-330,"elapsed":6775,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"152d61c1-e494-45d6-8530-de0378e93202"},"source":["losses = []\n","for n in range(10):\n","  print('.', end='')\n","  logs = translator.train_step([x[:64], y[:64]])\n","  losses.append(logs['batch_loss'].numpy())\n","\n","print()\n","plt.plot(losses)"],"execution_count":143,"outputs":[{"output_type":"stream","name":"stdout","text":["..........\n"]},{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f652417b190>]"]},"metadata":{},"execution_count":143},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOpklEQVR4nO3cf6jd9X3H8eeruTRrEUyi8UeN2bVVGHGDFg5K2QauaoyDNtL6h90fDVtL/lj9Y5VCUxzT2v6hbp2ltNsIbSEIa3SO0kApEm2FMYb1xDrarE1zjS0mVZuaIDipkvW9P+7X7Xg5Mffec+49OX6eDzjc8/1+P/fe98cLeeac742pKiRJ7XrbpAeQJE2WIZCkxhkCSWqcIZCkxhkCSWrczKQHWI7zzz+/ZmdnJz2GJE2VAwcO/LqqNi48P5UhmJ2dpd/vT3oMSZoqSX4x7LxvDUlS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS48YSgiTbkhxKMpdk15Dra5M80F1/PMnsguubk7yc5NPjmEeStHgjhyDJGuCrwI3AFuCjSbYsWPZx4GRVXQ7cB9yz4PrfA98ddRZJ0tKN4xXBVcBcVR2pqteAvcD2BWu2A3u65w8B1yYJQJKbgGeAg2OYRZK0ROMIwSXAswPHR7tzQ9dU1SngJeC8JOcAnwE+d6ZvkmRnkn6S/vHjx8cwtiQJJn+z+E7gvqp6+UwLq2p3VfWqqrdx48aVn0ySGjEzhq9xDLh04HhTd27YmqNJZoBzgReBq4Gbk9wLrAN+m+Q3VfWVMcwlSVqEcYTgCeCKJJcx/wf+LcCfLVizD9gB/AdwM/C9qirgj19fkORO4GUjIEmra+QQVNWpJLcCDwNrgG9U1cEkdwH9qtoHfB24P8kccIL5WEiSzgKZ/4v5dOn1etXv9yc9hiRNlSQHqqq38PykbxZLkibMEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS48YSgiTbkhxKMpdk15Dra5M80F1/PMlsd/76JAeS/Kj7+IFxzCNJWryRQ5BkDfBV4EZgC/DRJFsWLPs4cLKqLgfuA+7pzv8a+GBV/QGwA7h/1HkkSUszjlcEVwFzVXWkql4D9gLbF6zZDuzpnj8EXJskVfXDqvpld/4g8I4ka8cwkyRpkcYRgkuAZweOj3bnhq6pqlPAS8B5C9Z8BHiyql4dw0ySpEWamfQAAEmuZP7toq1vsmYnsBNg8+bNqzSZJL31jeMVwTHg0oHjTd25oWuSzADnAi92x5uAbwEfq6qnT/dNqmp3VfWqqrdx48YxjC1JgvGE4AngiiSXJXk7cAuwb8GafczfDAa4GfheVVWSdcB3gF1V9e9jmEWStEQjh6B7z/9W4GHgJ8CDVXUwyV1JPtQt+zpwXpI54Dbg9V8xvRW4HPibJE91jwtGnUmStHipqknPsGS9Xq/6/f6kx5CkqZLkQFX1Fp73XxZLUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuPGEoIk25IcSjKXZNeQ62uTPNBdfzzJ7MC1z3bnDyW5YRzzSJIWb+QQJFkDfBW4EdgCfDTJlgXLPg6crKrLgfuAe7rP3QLcAlwJbAP+oft6kqRVMo5XBFcBc1V1pKpeA/YC2xes2Q7s6Z4/BFybJN35vVX1alU9A8x1X0+StErGEYJLgGcHjo9254auqapTwEvAeYv8XACS7EzST9I/fvz4GMaWJMEU3Syuqt1V1auq3saNGyc9jiS9ZYwjBMeASweON3Xnhq5JMgOcC7y4yM+VJK2gcYTgCeCKJJcleTvzN3/3LVizD9jRPb8Z+F5VVXf+lu63ii4DrgB+MIaZJEmLNDPqF6iqU0luBR4G1gDfqKqDSe4C+lW1D/g6cH+SOeAE87GgW/cg8F/AKeCTVfU/o84kSVq8zP/FfLr0er3q9/uTHkOSpkqSA1XVW3h+am4WS5JWhiGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMaNFIIkG5LsT3K4+7j+NOt2dGsOJ9nRnXtnku8k+WmSg0nuHmUWSdLyjPqKYBfwaFVdATzaHb9Bkg3AHcDVwFXAHQPB+Luq+j3gfcAfJrlxxHkkSUs0agi2A3u653uAm4asuQHYX1UnquoksB/YVlWvVNX3AarqNeBJYNOI80iSlmjUEFxYVc91z58HLhyy5hLg2YHjo925/5NkHfBB5l9VSJJW0cyZFiR5BLhoyKXbBw+qqpLUUgdIMgN8E/hyVR15k3U7gZ0AmzdvXuq3kSSdxhlDUFXXne5akheSXFxVzyW5GPjVkGXHgGsGjjcBjw0c7wYOV9WXzjDH7m4tvV5vycGRJA036ltD+4Ad3fMdwLeHrHkY2JpkfXeTeGt3jiRfAM4F/mrEOSRJyzRqCO4Grk9yGLiuOyZJL8nXAKrqBPB54InucVdVnUiyifm3l7YATyZ5KsknRpxHkrREqZq+d1l6vV71+/1JjyFJUyXJgarqLTzvvyyWpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMaNFIIkG5LsT3K4+7j+NOt2dGsOJ9kx5Pq+JD8eZRZJ0vKM+opgF/BoVV0BPNodv0GSDcAdwNXAVcAdg8FI8mHg5RHnkCQt06gh2A7s6Z7vAW4asuYGYH9Vnaiqk8B+YBtAknOA24AvjDiHJGmZRg3BhVX1XPf8eeDCIWsuAZ4dOD7anQP4PPBF4JUzfaMkO5P0k/SPHz8+wsiSpEEzZ1qQ5BHgoiGXbh88qKpKUov9xkneC7ynqj6VZPZM66tqN7AboNfrLfr7SJLe3BlDUFXXne5akheSXFxVzyW5GPjVkGXHgGsGjjcBjwHvB3pJft7NcUGSx6rqGiRJq2bUt4b2Aa//FtAO4NtD1jwMbE2yvrtJvBV4uKr+sareVVWzwB8BPzMCkrT6Rg3B3cD1SQ4D13XHJOkl+RpAVZ1g/l7AE93jru6cJOkskKrpe7u91+tVv9+f9BiSNFWSHKiq3sLz/stiSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxqWqJj3DkiU5Dvxi0nMs0fnAryc9xCpzz21wz9Pjd6tq48KTUxmCaZSkX1W9Sc+xmtxzG9zz9POtIUlqnCGQpMYZgtWze9IDTIB7boN7nnLeI5CkxvmKQJIaZwgkqXGGYIySbEiyP8nh7uP606zb0a05nGTHkOv7kvx45Sce3Sh7TvLOJN9J8tMkB5PcvbrTL02SbUkOJZlLsmvI9bVJHuiuP55kduDaZ7vzh5LcsJpzj2K5e05yfZIDSX7UffzAas++HKP8jLvrm5O8nOTTqzXzWFSVjzE9gHuBXd3zXcA9Q9ZsAI50H9d3z9cPXP8w8M/Ajye9n5XeM/BO4E+6NW8H/g24cdJ7Os0+1wBPA+/uZv1PYMuCNX8J/FP3/Bbgge75lm79WuCy7uusmfSeVnjP7wPe1T3/feDYpPezkvsduP4Q8C/Apye9n6U8fEUwXtuBPd3zPcBNQ9bcAOyvqhNVdRLYD2wDSHIOcBvwhVWYdVyWveeqeqWqvg9QVa8BTwKbVmHm5bgKmKuqI92se5nf+6DB/xYPAdcmSXd+b1W9WlXPAHPd1zvbLXvPVfXDqvpld/4g8I4ka1dl6uUb5WdMkpuAZ5jf71QxBON1YVU91z1/HrhwyJpLgGcHjo925wA+D3wReGXFJhy/UfcMQJJ1wAeBR1diyDE44x4G11TVKeAl4LxFfu7ZaJQ9D/oI8GRVvbpCc47Lsvfb/SXuM8DnVmHOsZuZ9ADTJskjwEVDLt0+eFBVlWTRv5ub5L3Ae6rqUwvfd5y0ldrzwNefAb4JfLmqjixvSp2NklwJ3ANsnfQsK+xO4L6qerl7gTBVDMESVdV1p7uW5IUkF1fVc0kuBn41ZNkx4JqB403AY8D7gV6SnzP/c7kgyWNVdQ0TtoJ7ft1u4HBVfWkM466UY8ClA8ebunPD1hzt4nYu8OIiP/dsNMqeSbIJ+Bbwsap6euXHHdko+70auDnJvcA64LdJflNVX1n5scdg0jcp3koP4G95443Te4es2cD8+4jru8czwIYFa2aZnpvFI+2Z+fsh/wq8bdJ7OcM+Z5i/yX0Z/38j8coFaz7JG28kPtg9v5I33iw+wnTcLB5lz+u69R+e9D5WY78L1tzJlN0snvgAb6UH8++NPgocBh4Z+MOuB3xtYN1fMH/DcA748yFfZ5pCsOw9M/83rgJ+AjzVPT4x6T29yV7/FPgZ879Zcnt37i7gQ93z32H+N0bmgB8A7x743Nu7zzvEWfqbUePcM/DXwH8P/FyfAi6Y9H5W8mc88DWmLgT+LyYkqXH+1pAkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNe5/AecL/ch2b2HBAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"xh88TnW7a7Zs","executionInfo":{"status":"ok","timestamp":1631167425971,"user_tz":-330,"elapsed":656,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["translator2 = TrainTranslator(\n","    embedding_dim, units,\n","    input_text_vocab = tokenizer_hi.word_index,\n","    output_text_vocab = tokenizer_en.word_index,\n","    use_tf_function=False)\n","\n","# Configure the loss and optimizer\n","translator.compile(\n","    optimizer=tf.optimizers.Adam(),\n","    loss=MaskedLoss(),\n",")\n","translator.use_tf_function = True"],"execution_count":166,"outputs":[]},{"cell_type":"code","metadata":{"id":"eby0odqmav4l","executionInfo":{"status":"ok","timestamp":1631105154435,"user_tz":-330,"elapsed":536,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["BUFFER_SIZE = len(x)\n","BATCH_SIZE = 64\n","\n","dataset = tf.data.Dataset.from_tensor_slices((x,y)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"_REvvy9JZUIp","executionInfo":{"status":"ok","timestamp":1631106654110,"user_tz":-330,"elapsed":725,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["class BatchLogs(tf.keras.callbacks.Callback):\n","  def __init__(self, key):\n","    self.key = key\n","    self.logs = []\n","\n","  def on_train_batch_end(self, n, logs):\n","    self.logs.append(logs[self.key])\n","\n","batch_loss = BatchLogs('batch_loss')"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"fK1apRB4ZUL1"},"source":["training."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RV4LN7bni7DY"},"source":["tokenizer_en.texts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uRtMXk8GZUN1","executionInfo":{"status":"ok","timestamp":1631252980056,"user_tz":-330,"elapsed":385,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["class Translator(tf.Module):\n","\n","  def __init__(self, encoder, decoder,input_tokenizer,output_tokenizer):\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.input_tokenizer = input_tokenizer\n","    self.output_tokenizer = output_tokenizer\n","    #self.output_token_string_from_index = output_tokenizer.sequences_to_texts()\n","    #self.output_token_string_from_index = (\n","     #   tf.keras.layers.experimental.preprocessing.Char(\n","      #      vocabulary=output_text_vocab,\n","       #     mask_token='',\n","       #     invert=True))\n","\n","    # The output should never generate padding, unknown, or start.\n","    #index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n","       # vocabulary=output_tokenizer.word_index, mask_token='')\n","    token_mask_ids = 0\n","\n","    token_mask = np.zeros([len(output_tokenizer.word_index)+1], dtype=np.bool)\n","    token_mask[np.array(token_mask_ids)] = True\n","    self.token_mask = token_mask\n","\n","    self.start_token = output_tokenizer.word_index['<sos>']\n","    self.end_token = output_tokenizer.word_index['<eos>']"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2cRSfqpZUQg","executionInfo":{"status":"ok","timestamp":1631252983960,"user_tz":-330,"elapsed":430,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["def sample(self, logits, temperature):\n","  #shape_checker = ShapeChecker()\n","  # 't' is usually 1 here.\n","  #shape_checker(logits, ('batch', 't', 'vocab'))\n","  #shape_checker(self.token_mask, ('vocab',))\n","  #logits =tf.squeeze(logits,axis=1)\n","  \n","  token_mask = self.token_mask[tf.newaxis,tf.newaxis, :]\n","  \n","  #shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n","\n","  # Set the logits for all masked tokens to -inf, so they are never chosen.\n","  logits = tf.where(self.token_mask, -np.inf, logits)\n","\n","  if temperature == 0.0:\n","    new_tokens = tf.argmax(logits, axis=-1)\n","  else: \n","    logits = tf.squeeze(logits, axis=1)\n","    new_tokens = tf.random.categorical(logits/temperature,\n","                                        num_samples=1)\n","\n","  #shape_checker(new_tokens, ('batch', 't'))\n","\n","  return new_tokens\n","def tokens_to_text(self, result_tokens):\n","  #shape_checker = ShapeChecker()\n","  #shape_checker(result_tokens, ('batch', 't'))\n","  result_text_tokens = self.output_tokenizer.sequences_to_texts(result_tokens.numpy())\n","  #shape_checker(result_text_tokens, ('batch', 't'))\n","\n","  #result_text = tf.strings.reduce_join(result_text_tokens,\n","   #                                    axis=1, separator='')\n","  #shape_checker(result_text, ('batch'))\n","\n","  #result_text = tf.strings.strip(result_text)\n","  #shape_checker(result_text, ('batch',))\n","  return result_text_tokens\n","def translate_unrolled(self,\n","                       input_text, *,\n","                       max_length=19,\n","                       return_attention=False,\n","                       temperature=0.0):\n","  \n","  #print(batch_size)\n","  input_tokens = self.input_tokenizer.texts_to_sequences(input_text)\n","  input_tokens = kprocessing.sequence.pad_sequences(input_tokens,padding='post')\n","  #print(input_tokens.T,input_tokens.T.shape)\n","  input_tokens= input_tokens.T\n","  batch_size = input_tokens.shape[0]\n","  input_tokens = tf.constant(input_tokens)\n","  enc_output, enc_state = self.encoder(input_tokens)\n","\n","  dec_state = enc_state\n","  new_tokens = tf.fill([batch_size, 1], self.start_token)\n","  #print(new_tokens)\n","  result_tokens = []\n","  attention = []\n","  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n","  \n","  #print(max_length)\n","  for _ in range(max_length):\n","    dec_input = DecoderInput(new_tokens=new_tokens,\n","                             enc_output=enc_output,\n","                             mask=(input_tokens!=0))\n","\n","    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n","    #print(dec_result.logits.shape)\n","    attention.append(dec_result.attention_weights)\n","\n","    new_tokens = self.sample(dec_result.logits, temperature)\n","\n","    # If a sequence produces an `end_token`, set it `done`\n","    done = done | (new_tokens == self.end_token)\n","    # Once a sequence is done it only produces 0-padding.\n","    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n","\n","    # Collect the generated tokens\n","    result_tokens.append(new_tokens)\n","\n","    if tf.executing_eagerly() and tf.reduce_all(done):\n","      break\n","\n","  # Convert the list of generates token ids to a list of strings.\n","  \n","  result_tokens = tf.concat(result_tokens, axis=-1)\n","  result_text = self.tokens_to_text(result_tokens)\n","\n","  if return_attention:\n","    attention_stack = tf.concat(attention, axis=1)\n","    return {'text': result_text, 'attention': attention_stack}\n","  else:\n","    return {'text': result_text}\n","\n","\n","Translator.tokens_to_text = tokens_to_text\n","Translator.sample = sample\n","Translator.translate = translate_unrolled"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"ui4m0EEjZUS6","executionInfo":{"status":"ok","timestamp":1631160732063,"user_tz":-330,"elapsed":3,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":[""],"execution_count":99,"outputs":[]},{"cell_type":"code","metadata":{"id":"KWDWnR4MNddD","executionInfo":{"status":"ok","timestamp":1631252987108,"user_tz":-330,"elapsed":433,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["translator = Translator(\n","    encoder=translator.encoder,\n","    decoder=translator.decoder,\n","    input_tokenizer=tokenizer_hi,\n","    output_tokenizer=tokenizer_en,\n",")"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"apgF-6qwNhnt","executionInfo":{"status":"ok","timestamp":1631254417908,"user_tz":-330,"elapsed":27031,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"93aa073c-80be-495f-97d3-89afae367c05"},"source":["ns = [i for i in range(100,200)]\n","for i in ns:\n","  print(translator.translate(hindi[i]), roman[i])"],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["{'text': ['a n t a r r a s h t r i y <UNK>']} antarrashtriye\n","{'text': ['t a n t a r a t m a <UNK>']} antaratma\n","{'text': ['t a n t a r a t m a <UNK>']} antratma\n","{'text': ['t t a n t r a n t r a n t a l a l a l']} antral\n","{'text': ['n t a r a s h t r i y <UNK>']} antarashtriya\n","{'text': ['n t a r a s h t r i y <UNK>']} antarrashtriya\n","{'text': ['n t a r a s h t r i y <UNK>']} antrashtriya\n","{'text': ['n t r n t r i k s h r i k s h <UNK>']} antariksh\n","{'text': ['n t r n t r i k s h r i k s h <UNK>']} antriksh\n","{'text': ['a n t a r i k s h y a t r i <UNK>']} antrikshyatri\n","{'text': ['t a n t a r k s h a n <UNK>']} antrikshayan\n","{'text': ['t a n t a r k s h a n <UNK>']} antrikshyaan\n","{'text': ['t a n t a r k s h a n <UNK>']} antrikshyan\n","{'text': ['n t t r i m m i m <UNK>']} antarim\n","{'text': ['n t t r i m m i m <UNK>']} antrim\n","{'text': ['a n t r o n <UNK>']} antaron\n","{'text': ['n t g a r g a r g a t <UNK>']} antargart\n","{'text': ['n t g a r g a r g a t <UNK>']} antargat\n","{'text': ['n t g a r g a r g a t <UNK>']} antrgat\n","{'text': ['a n t a r d r i s h t i <UNK>']} antardrishti\n","{'text': ['a n t a r d r i s h t i <UNK>']} antdrashti\n","{'text': ['a n t a r d r i s h t i <UNK>']} antdrishti\n","{'text': ['n a n t r d e s h i y <UNK>']} antardeshiy\n","{'text': ['n a n t r d e s h i y <UNK>']} antardeshiya\n","{'text': ['n a n t r d e s h i y <UNK>']} antdreshiya\n","{'text': ['a n t h n i r h i t <UNK>']} antarnihit\n","{'text': ['a n t h n i r h i t <UNK>']} antnirhit\n","{'text': ['t n t a n a n <UNK>']} antarman\n","{'text': ['t n t a n a n <UNK>']} antrman\n","{'text': ['a n t a r r a s h t r i y <UNK>']} antarrashtriy\n","{'text': ['a n t a r r a s h t r i y <UNK>']} antrashtriya\n","{'text': ['a n t a r r a s h t r i y <UNK>']} antrrashtriy\n","{'text': ['a n t a r v a s t r a <UNK>']} antarvastr\n","{'text': ['a n t a r v a s t r a <UNK>']} antavastra\n","{'text': ['a n t a r v a s t r a <UNK>']} antvastra\n","{'text': ['a n t v i r r v i r o d h o n <UNK>']} antarvirodhon\n","{'text': ['a n t v i r r v i r o d h o n <UNK>']} antrvirodhon\n","{'text': ['a n t v i r r v i r o d h o n <UNK>']} antvirrodhon\n","{'text': ['n a n t a r v a i y k t i c <UNK>']} antarvaiyaktik\n","{'text': ['n a n t a r v a i y k t i c <UNK>']} antvaiyktik\n","{'text': ['n t i m t i m <UNK>']} antim\n","{'text': ['a n t u l e e l e <UNK>']} antule\n","{'text': ['a n t y a n t y a <UNK>']} antya\n","{'text': ['a a t h e e t t i s h t i <UNK>']} antyeshti\n","{'text': ['n a n t y o d a y o d a y <UNK>']} antyoday\n","{'text': ['n a n t y o d a y o d a y <UNK>']} antyodaya\n","{'text': ['a n d a r a r <UNK>']} andar\n","{'text': ['a n d r u n i o n i <UNK>']} andhruni\n","{'text': ['a n d r u n i o n i <UNK>']} androoni\n","{'text': ['a n d r u n i o n i <UNK>']} andrunee\n","{'text': ['a n d r u n i o n i <UNK>']} andruni\n","{'text': ['a n d a a z <UNK>']} andaaj\n","{'text': ['a n d a a z <UNK>']} andaaz\n","{'text': ['a n d a a z <UNK>']} andaz\n","{'text': ['a n d a a z <UNK>']} andhaaz\n","{'text': ['n a n d a j a n <UNK>']} anadajan\n","{'text': ['n a n d a j a n <UNK>']} andaajan\n","{'text': ['n a n d a j a n <UNK>']} andaazan\n","{'text': ['n a n d a j a n <UNK>']} andajan\n","{'text': ['a n d a n d a a j <UNK>']} andaaj\n","{'text': ['a n d a n d a a j <UNK>']} andaaz\n","{'text': ['a n d a n d a a j <UNK>']} andaj\n","{'text': ['a n d a n d a a j <UNK>']} andaz\n","{'text': ['n a n d a j a a j a a <UNK>']} andaaja\n","{'text': ['n a n d a j a a j a a <UNK>']} andaajaa\n","{'text': ['n a n d a j a a j a a <UNK>']} andaaza\n","{'text': ['n a n d a j a a j a a <UNK>']} andaazaa\n","{'text': ['n a n d a j a a j a a <UNK>']} andaja\n","{'text': ['n a n d a j a a j a a <UNK>']} andaza\n","{'text': ['e n n e n d e s h a a <UNK>']} andesha\n","{'text': ['e n n e n d e s h a a <UNK>']} andeshaa\n","{'text': ['a n d h a k h a k <UNK>']} andhak\n","{'text': ['a n d h a k a r <UNK>']} andhakaar\n","{'text': ['a n d h a k a r <UNK>']} andhkaar\n","{'text': ['a n d h a k a r <UNK>']} andhkar\n","{'text': ['a n d h k a r p u r n <UNK>']} andhakaarapurna\n","{'text': ['a n d h k a r p u r n <UNK>']} andhakarapurn\n","{'text': ['a n d h k a r p u r n <UNK>']} andhkaarpurn\n","{'text': ['a n d h k a r p u r n <UNK>']} andhkarpurn\n","{'text': ['a n d h k a r p u r n <UNK>']} andkaarpurn\n","{'text': ['a n d h k a r p u r n <UNK>']} andkarpuran\n","{'text': ['a n d h k a r p u r n <UNK>']} andkarpurn\n","{'text': ['d d t h t h t a <UNK>']} andhata\n","{'text': ['d d t h t h t a <UNK>']} andhataa\n","{'text': ['d d t h t h t a <UNK>']} andhta\n","{'text': ['d d t h t h t a <UNK>']} andhtaa\n","{'text': ['a n d h v i s h v a a s <UNK>']} andhavishvas\n","{'text': ['a n d h v i s h v a a s <UNK>']} andhvishvaas\n","{'text': ['a n d h v i s h v a a s <UNK>']} andhvishwas\n","{'text': ['n a n d h v i s h v a a s o n <UNK>']} andhavishvason\n","{'text': ['n a n d h v i s h v a a s o n <UNK>']} andhvishvaason\n","{'text': ['n a n d h v i s h v a a s o n <UNK>']} andhvishvason\n","{'text': ['n a n d h v i s h v a a s o n <UNK>']} andhvishwason\n","{'text': ['h a n d h a d h u n d h <UNK>']} andhadhundh\n","{'text': ['a n d h e n d h e <UNK>']} andhe\n","{'text': ['h a n d h e p a n <UNK>']} andhepan\n","{'text': ['u m p i r e r e <UNK>']} empire\n","{'text': ['u m p i r e r e <UNK>']} umpire\n","{'text': ['b a m b a l a <UNK>']} ambala\n","{'text': ['m a n b i n b i k a i k a <UNK>']} ambika\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"00KmxTmiNhqb","executionInfo":{"status":"ok","timestamp":1631160433897,"user_tz":-330,"elapsed":373,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"49cd9071-f95f-4bff-8523-b8bcf86426b6"},"source":["q"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'inaka'"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"E2mjcvw8Nhsv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqW_2CbJNhwF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xXSqTpT5NhyH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOjXGoDkNh0n"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ztwMfBItqtnC"},"source":["def tf_lower_and_split_punct(text):\n","  # Split accecented characters.\n","  text = tf_text.normalize_utf8(text, 'NFKD')\n","  text = tf.strings.lower(text)\n","  # Keep space, a to z, and select punctuation.\n","  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n","  # Add spaces around punctuation.\n","  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n","  # Strip whitespace.\n","  text = tf.strings.strip(text)\n","\n","  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n","  return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1Yy9eVxv_ZE","executionInfo":{"status":"ok","timestamp":1630948895328,"user_tz":-330,"elapsed":448,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"1b07b606-2cf1-4add-fb3f-951576a49995"},"source":["ls = tokenizer.detokenize(inp[0].numpy().tolist()).numpy()\n","print(ls)\n","ls = ls.decode('utf-8')\n","print(ls)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["b'\\xe0\\xa4\\x85\\xe0\\xa4\\x82'\n","अं\n"]}]},{"cell_type":"code","metadata":{"id":"Sw97_ZFqi1-k","executionInfo":{"status":"ok","timestamp":1631073571455,"user_tz":-330,"elapsed":362,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}}},"source":["df = pd.read_csv(pth_1,sep=\"\\t\",names=[\"Hindi\",\"roman\",\"freq\"]) \n","df = df[['Hindi','roman']]\n","hindi = df['Hindi']"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LhX0tDGXjCxX","executionInfo":{"status":"ok","timestamp":1631077669880,"user_tz":-330,"elapsed":379,"user":{"displayName":"ShuvraNeel Roy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjANYVmLo_zt-mrVqbJH5tqTlykNEjoP2JtAN8Ybw=s64","userId":"06350349201381820342"}},"outputId":"b968a20a-5c3e-43b8-cc37-32cc903eef3e"},"source":["x"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[30, 10,  0, ...,  0,  0,  0],\n","       [30, 10,  7, ...,  0,  0,  0],\n","       [30, 10,  7, ...,  0,  0,  0],\n","       ...,\n","       [25,  4, 15, ...,  0,  0,  0],\n","       [25,  4, 15, ...,  0,  0,  0],\n","       [64,  0,  0, ...,  0,  0,  0]], dtype=int32)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"vUY2oSJaqmFi"},"source":[""],"execution_count":null,"outputs":[]}]}